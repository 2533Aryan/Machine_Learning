{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training LinearRegressionGD on the Ames housing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "columns = ['Overall Qual', 'Overall Cond', 'Gr Liv Area',\n",
    "           'Central Air', 'Total Bsmt SF', 'SalePrice']\n",
    "\n",
    "df = pd.read_csv('http://jse.amstat.org/v19n3/decock/AmesHousing.txt', \n",
    "                 sep='\\t',\n",
    "                 usecols=columns)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Central Air'] = df['Central Air'].map({'N': 0, 'Y': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows that contain missing values\n",
    "\n",
    "df = df.dropna(axis=0)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionGD:\n",
    "    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=X.shape[1])\n",
    "        self.b_ = np.array([0.])\n",
    "        self.losses_ = []\n",
    "\n",
    "        for i in range(self.n_iter):\n",
    "            output = self.net_input(X)\n",
    "            errors = (y - output)\n",
    "            self.w_ += self.eta * 2.0 * X.T.dot(errors) / X.shape[0]\n",
    "            self.b_ += self.eta * 2.0 * errors.mean()\n",
    "            loss = (errors**2).mean()\n",
    "            self.losses_.append(loss)\n",
    "        return self\n",
    "\n",
    "    def net_input(self, X):\n",
    "        return np.dot(X, self.w_) + self.b_\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.net_input(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Gr Liv Area']].values\n",
    "y = df['SalePrice'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc_x = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "X_std = sc_x.fit_transform(X)\n",
    "y_std = sc_y.fit_transform(y[:, np.newaxis]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegressionGD(eta=0.1)\n",
    "lr.fit(X_std, y_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(1, lr.n_iter+1), lr.losses_)\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('figures/09_06.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_regplot(X, y, model):\n",
    "    plt.scatter(X, y, c='steelblue', edgecolor='white', s=70)\n",
    "    plt.plot(X, model.predict(X), color='black', lw=2)    \n",
    "    return \n",
    "\n",
    "lin_regplot(X_std, y_std, lr)\n",
    "plt.xlabel('Living area above ground (standardized)')\n",
    "plt.ylabel('Sale price (standardized)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Slope: {lr.w_[0]:.3f}')\n",
    "print(f'Intercept: {lr.b_[0]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training sklearn's LinearRegression on the Ames housing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "\n",
    "sc_y = StandardScaler()\n",
    "sc_y.fit(y_train[:, np.newaxis])\n",
    "y_train_std = sc_y.transform(y_train[:, np.newaxis]).flatten()\n",
    "y_test_std = sc_y.transform(y_test[:, np.newaxis]).flatten()\n",
    "\n",
    "##################\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "est = LinearRegression()\n",
    "est.fit(X_train_std, y_train_std)\n",
    "\n",
    "##################\n",
    "\n",
    "y_train_pred = est.predict(X_train_std)\n",
    "y_test_pred = est.predict(X_test_std)\n",
    "\n",
    "print('MSE train: %.3f, test: %.3f' % (\n",
    "        mean_squared_error(y_train_std, y_train_pred),\n",
    "        mean_squared_error(y_test_std, y_test_pred)))\n",
    "print('R^2 train: %.3f, test: %.3f' % (\n",
    "        r2_score(y_train_std, y_train_pred),\n",
    "        r2_score(y_test_std, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_regplot(X_train_std, y_train_std, est)\n",
    "plt.xlabel('Living area above ground (standardized)')\n",
    "plt.ylabel('Sale price (standardized)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_regplot(X_test_std, y_test_std, est)\n",
    "plt.xlabel('Living area above ground (standardized)')\n",
    "plt.ylabel('Sale price (standardized)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training sklearn's RandomForestRegressor on the Ames housing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "est = RandomForestRegressor(n_estimators=1000, \n",
    "                            criterion='squared_error', \n",
    "                            random_state=1, \n",
    "                            n_jobs=-1)\n",
    "est.fit(X_train_std, y_train_std)\n",
    "\n",
    "y_train_pred = est.predict(X_train_std)\n",
    "y_test_pred = est.predict(X_test_std)\n",
    "\n",
    "print('MSE train: %.3f, test: %.3f' % (\n",
    "        mean_squared_error(y_train_std, y_train_pred),\n",
    "        mean_squared_error(y_test_std, y_test_pred)))\n",
    "print('R^2 train: %.3f, test: %.3f' % (\n",
    "        r2_score(y_train_std, y_train_pred),\n",
    "        r2_score(y_test_std, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_regplot(X_train_std, y_train_std, est)\n",
    "plt.xlabel('Living area above ground (standardized)')\n",
    "plt.ylabel('Sale price (standardized)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonlin_regplot(X, y, model):\n",
    "    plt.scatter(X, y, c='steelblue', edgecolor='white', s=70)\n",
    "    plt.scatter(X, model.predict(X), color='red', s=10)    \n",
    "    return \n",
    "\n",
    "nonlin_regplot(X_train_std, y_train_std, est)\n",
    "plt.xlabel('Living area above ground (standardized)')\n",
    "plt.ylabel('Sale price (standardized)')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonlin_regplot(X_test_std, y_test_std, est)\n",
    "plt.xlabel('Living area above ground (standardized)')\n",
    "plt.ylabel('Sale price (standardized)')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training gplearn on the Ames housing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install gplearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gplearn.genetic import SymbolicRegressor\n",
    "\n",
    "est = SymbolicRegressor(population_size=1000,\n",
    "                        init_depth=(4,6),\n",
    "                        generations=100, stopping_criteria=0.01,\n",
    "                        p_crossover=0.3, p_subtree_mutation=0.35,\n",
    "                        p_hoist_mutation=0.0, p_point_mutation=0.35,\n",
    "                        max_samples=1.0, verbose=1,\n",
    "                        #const_range=None,\n",
    "                        const_range=(-1.0,1.0),\n",
    "                        tournament_size=5,\n",
    "                        function_set=('add', 'sub', 'mul', 'div', 'sqrt', 'log', \n",
    "                                      'abs', 'neg', 'inv', 'max','min', 'sin', 'cos', 'tan'),\n",
    "                        parsimony_coefficient=0.0001, random_state=0)\n",
    "est.fit(X_train_std, y_train_std)\n",
    "\n",
    "y_train_pred = est.predict(X_train_std)\n",
    "y_test_pred = est.predict(X_test_std)\n",
    "\n",
    "print('MSE train: %.3f, test: %.3f' % (\n",
    "        mean_squared_error(y_train_std, y_train_pred),\n",
    "        mean_squared_error(y_test_std, y_test_pred)))\n",
    "print('R^2 train: %.3f, test: %.3f' % (\n",
    "        r2_score(y_train_std, y_train_pred),\n",
    "        r2_score(y_test_std, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(est._program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonlin_regplot(X_train_std, y_train_std, est)\n",
    "plt.xlabel('Living area above ground (standardized)')\n",
    "plt.ylabel('Sale price (standardized)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonlin_regplot(X_test_std, y_test_std, est)\n",
    "plt.xlabel('Living area above ground (standardized)')\n",
    "plt.ylabel('Sale price (standardized)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial data from $$target = 2*sin(a)+b^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt \n",
    "from mpl_toolkits import mplot3d\n",
    "plt.rcdefaults() \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def target_function(a, b):\n",
    "    \"\"\"Generate a training data point.\"\"\"\n",
    "    return (2.0 * np.sin(a)) + (b * b)\n",
    "\n",
    "np.random.seed(0)\n",
    "X = np.random.rand(50,2)*2-1\n",
    "y = np.array([target_function(x[0], x[1]) for x in X])\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "ax.scatter(X[:,0], X[:,1], y)\n",
    "\n",
    "ax.set_xlabel('a')\n",
    "ax.set_ylabel('b')\n",
    "ax.set_zlabel('target')\n",
    "\n",
    "#ax.view_init(30, 300) # default, or close\n",
    "#ax.view_init(10, 280)\n",
    "#ax.view_init(10, 340)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training gplearn on the artificial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=1)\n",
    "\n",
    "##################\n",
    "\n",
    "from gplearn.genetic import SymbolicRegressor\n",
    "\n",
    "est = SymbolicRegressor(population_size=1000,\n",
    "                        init_depth=(4,6),\n",
    "                        generations=100, stopping_criteria=0.01,\n",
    "                        p_crossover=0.3, p_subtree_mutation=0.35,\n",
    "                        p_hoist_mutation=0.0, p_point_mutation=0.35,\n",
    "                        max_samples=1.0, verbose=1,\n",
    "                        const_range=None,\n",
    "                        #const_range=(-1.0,1.0),\n",
    "                        tournament_size=5,\n",
    "                        function_set=('add', 'sub', 'mul', 'div', 'sqrt', 'log', \n",
    "                                      'abs', 'neg', 'inv', 'max','min', 'sin', 'cos', 'tan'),\n",
    "                        parsimony_coefficient=0.0001, random_state=0)\n",
    "est.fit(X_train, y_train)\n",
    "\n",
    "##################\n",
    "\n",
    "y_train_pred = est.predict(X_train)\n",
    "y_test_pred = est.predict(X_test)\n",
    "\n",
    "print('MSE train: %.3f, test: %.3f' % (\n",
    "        mean_squared_error(y_train, y_train_pred),\n",
    "        mean_squared_error(y_test, y_test_pred)))\n",
    "print('R^2 train: %.3f, test: %.3f' % (\n",
    "        r2_score(y_train, y_train_pred),\n",
    "        r2_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(est._program)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training sklearn's RandomForestRegressor on the artificial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "est = RandomForestRegressor(n_estimators=1000, \n",
    "                            criterion='squared_error', \n",
    "                            random_state=1, \n",
    "                            n_jobs=-1)\n",
    "est.fit(X_train, y_train)\n",
    "\n",
    "##################\n",
    "\n",
    "y_train_pred = est.predict(X_train)\n",
    "y_test_pred = est.predict(X_test)\n",
    "\n",
    "print('MSE train: %.3f, test: %.3f' % (\n",
    "        mean_squared_error(y_train, y_train_pred),\n",
    "        mean_squared_error(y_test, y_test_pred)))\n",
    "print('R^2 train: %.3f, test: %.3f' % (\n",
    "        r2_score(y_train, y_train_pred),\n",
    "        r2_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training sklearn's LinearRegression on the artificial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "est = LinearRegression()\n",
    "est.fit(X_train, y_train)\n",
    "\n",
    "##################\n",
    "\n",
    "y_train_pred = est.predict(X_train)\n",
    "y_test_pred = est.predict(X_test)\n",
    "\n",
    "print('MSE train: %.3f, test: %.3f' % (\n",
    "        mean_squared_error(y_train, y_train_pred),\n",
    "        mean_squared_error(y_test, y_test_pred)))\n",
    "print('R^2 train: %.3f, test: %.3f' % (\n",
    "        r2_score(y_train, y_train_pred),\n",
    "        r2_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maybe check out:\n",
    "\n",
    "- [EC-KitY](https://github.com/EC-KitY/EC-KitY): Evolutionary Computation Tool Kit in Python\n",
    "\n",
    "- [PyshGP](https://github.com/erp12/pyshgp): Push Genetic Programming in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
