{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Status: In one paragraph, describe what you have completed for the project so far. In a second paragraph, describe what remains to be done.\n",
    "\n",
    "Code: Although it is not expected that your project be complete, or even close to complete, you must submit at least some code that runs, demonstrating the aspects of your project that have been completed. Include text that explains what we are seeing when we run your code, and how it relates to what we will see when your project is complete. If your project involves code that is not expected to be run from a Jupyter notebook (for example, code in .py files that you run from a command line on the Amherst cluster, or code written in a language other than Python), then you should explain this in a markdown cell and also explain how we can run your code; if possible, it would also be helpful to include in your notebook some version of your code that can run that context."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title: Sentiment Analysis on Tweets using Machine Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description: \n",
    "In 3-5 paragraphs, describe what you are trying to accomplish and how you expect to accomplish it. Provide as many specific details as you can, within 3-5 paragraphs, about the data and algorithms that you will use, the outcomes that you will aim to achieve, and the ways that you will document your efforts and results.\n",
    "\n",
    "\n",
    "The goal of this project is to develop a <strong>sentiment analysis</strong> model using machine learning techniques to classify text as positive, negative, or neutral. To accomplish this, I used a Twitter dataset (Twitter_Data.csv) that have been labeled as positive (marked as 1), negative (marked as -1), or neutral (marked as 0) based on their sentiment.\n",
    "\n",
    "To accomplish this task, I used <strong>Natural Language Processing</strong> (NLP) techniques and <strong>Machine Learning</strong> algorithms. First, we will <strong>preprocess</strong> the data by removing stop words, stemming and lemmatizing the text, and converting it into a numeric format using either a <strong>count vectorizer</strong> or a <strong>tf-idf vectorizer</strong>. We will then split the dataset into training and validation sets and use a <strong>logistic regression</strong> classifier with <strong>one-vs-rest</strong> strategy to train and predict the sentiment of the text.\n",
    "\n",
    "The outcomes we aim to achieve are a sentiment analysis model that can accurately classify text into positive, negative, or neutral categories. The aim is to achieve high accuracy, precision, and recall for each of the three sentiment classes. To evaluate the model, we will use metrics such as <strong>F1-score</strong>, <strong>accuracy</strong>, and <strong>confusion matrix</strong>. We will also provide a detailed classification report to analyze the performance of our model for each class.\n",
    "\n",
    "To document my efforts and results, I created a report outlining the methodology, including the data preprocessing steps, machine learning algorithms used, and model evaluation. I will also include visualizations such as word clouds and histograms to help explain our findings. Additionally, we will provide the code used for this project in a public repository on GitHub for others to replicate and build upon our work.\n",
    "\n",
    "Overall, this project aims to provide a practical example of how to develop a sentiment analysis model using machine learning techniques and demonstrate the importance of preprocessing and hyperparameter tuning in achieving accurate sentiment classification."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, we set out to classify the sentiment of tweets using machine learning techniques. We have successfully gathered and preprocessed a large dataset of tweets, including removing stop words, punctuation, and URLs. We then trained a logistic regression model using the TF-IDF vectorizer to predict the sentiment of each tweet as positive, negative, or neutral. We evaluated the model using various metrics such as accuracy, F1-score, and confusion matrix. Finally, we have documented our efforts and results in the form of code and text explanations.\n",
    "\n",
    "Moving forward, we plan to explore other machine learning algorithms and hyperparameter tuning techniques to improve the performance of our model. We also plan to gather more data and investigate the impact of different preprocessing techniques on the model's accuracy. Additionally, we aim to deploy the model in a web application to provide users with real-time sentiment analysis of tweets.\n",
    "\n",
    "\n",
    "# Positive tweets\n",
    "\n",
    "- Below code generates a word cloud visualization of a collection of positive tweets from the dataset.\n",
    "- Code also creates a new plot figure with a black background and displays the word cloud image.\n",
    "- The last line deletes the text string to free up memory."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code performs sentiment analysis on a dataset of tweets. It uses a machine learning algorithm called logistic regression with a one-vs-rest classifier to predict whether each tweet is negative, neutral, or positive. The data is preprocessed using techniques such as removing stop words, lemmatization, and converting words to lowercase. The data is then transformed into numerical features using the TF-IDF vectorizer, which converts words to numerical values based on their frequency and importance in the dataset. The model is trained on a training set and evaluated on a validation set using various metrics such as accuracy, F1 score, and a confusion matrix. The output of the code is the classification report, which shows precision, recall, and F1 score for each sentiment category as well as the overall accuracy.\n",
    "\n",
    "In summary, the code uses natural language processing and machine learning techniques to analyze the sentiment of tweets and provides a report on the accuracy and performance of the model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All the necessary libraries in one go using the following command:\n",
    "pip install -r requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing various libraries that will be used for data analysis, natural language processing, and machine learning tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\2533a\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "# ignore all warning messages\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# other modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report,confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Embedding, Flatten, Dense, Dropout, SpatialDropout1D, LSTM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Pandas library to read a CSV file and create a DataFrame object to store the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised â€œminimum government maximum...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kiya tho refresh maarkefir comment karo</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>surat women perform yagna seeks divine grace f...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>this comes from cabinet which has scholars lik...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>with upcoming election india saga going import...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gandhi was gay does modi</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  category\n",
       "0  when modi promised â€œminimum government maximum...      -1.0\n",
       "1  talk all the nonsense and continue all the dra...       0.0\n",
       "2  what did just say vote for modi  welcome bjp t...       1.0\n",
       "3  asking his supporters prefix chowkidar their n...       1.0\n",
       "4  answer who among these the most powerful world...       1.0\n",
       "5           kiya tho refresh maarkefir comment karo        0.0\n",
       "6  surat women perform yagna seeks divine grace f...       0.0\n",
       "7  this comes from cabinet which has scholars lik...       0.0\n",
       "8  with upcoming election india saga going import...       1.0\n",
       "9                         gandhi was gay does modi         1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Twitter_Data.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 162980 entries, 0 to 162979\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   clean_text  162976 non-null  object \n",
      " 1   category    162973 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting unique values from the 'category' column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  0.,  1., nan])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category.unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating descriptive statistics of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>162973.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.225436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.781279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            category\n",
       "count  162973.000000\n",
       "mean        0.225436\n",
       "std         0.781279\n",
       "min        -1.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         1.000000\n",
       "max         1.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting the number of missing (null) values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clean_text    4\n",
       "category      7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['clean_text', 'category'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of all the column names \n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130448</th>\n",
       "      <td>the foundation stone northeast gas grid inaugu...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155642</th>\n",
       "      <td>dear terrorists you can run but you cant hide ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155698</th>\n",
       "      <td>offense the best defence with mission shakti m...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155770</th>\n",
       "      <td>have always heard politicians backing out thei...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158693</th>\n",
       "      <td>modi government plans felicitate the faceless ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159442</th>\n",
       "      <td>chidambaram gives praises modinomics</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160559</th>\n",
       "      <td>the reason why modi contested from seats 2014 ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clean_text  category\n",
       "130448  the foundation stone northeast gas grid inaugu...       NaN\n",
       "155642  dear terrorists you can run but you cant hide ...       NaN\n",
       "155698  offense the best defence with mission shakti m...       NaN\n",
       "155770  have always heard politicians backing out thei...       NaN\n",
       "158693  modi government plans felicitate the faceless ...       NaN\n",
       "159442               chidambaram gives praises modinomics       NaN\n",
       "160559  the reason why modi contested from seats 2014 ...       NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter data to only show rows where the 'category' column has missing (null) values\n",
    "df[df['category'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158694</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159443</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160560</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       clean_text  category\n",
       "148           NaN       0.0\n",
       "158694        NaN      -1.0\n",
       "159443        NaN       0.0\n",
       "160560        NaN       1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the 'clean_text' column has missing (null) values.\n",
    "df[df['clean_text'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing (null) data\n",
    "clean_df=df.drop(df[df['clean_text'].isna()].index, inplace=True)\n",
    "cat_df=df.drop(df[df['category'].isna()].index, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess function:\n",
    "\n",
    "Takes a list of text data as input and returns a list of preprocessed text data. \n",
    "Performs several text preprocessing steps to clean and normalize the input text data for use in natural language processing tasks.\n",
    "The text preprocessing steps performed by this function include:\n",
    "\n",
    "- Converting all text to lowercase.\n",
    "- Replacing URLs with the string \"URL\".\n",
    "- Replacing emojis with a string containing the word \"EMOJI\" and the corresponding emoji code.\n",
    "- Replacing mentions of user handles (e.g. \"@username\") with the string \"USER\".\n",
    "- Removing all non-alphanumeric characters (excluding spaces).\n",
    "- Replacing any sequences of three or more consecutive characters with just two copies of the same character (e.g. \"looooove\" becomes \"loove\").\n",
    "- Lemmatizing each word in the text data using the WordNet lemmatizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(textdata):\n",
    "    processedText = []\n",
    "    \n",
    "    # Create Lemmatizer and Stemmer.\n",
    "    wordLemm = WordNetLemmatizer()\n",
    "    \n",
    "    # Defining regex patterns.\n",
    "    urlPattern        = r\"((http://)[^ ]*|(https://)[^ ]*|( www\\.)[^ ]*)\"\n",
    "    userPattern       = '@[^\\s]+'\n",
    "    alphaPattern      = \"[^a-zA-Z0-9]\"\n",
    "    sequencePattern   = r\"(.)\\1\\1+\"\n",
    "    seqReplacePattern = r\"\\1\\1\"\n",
    "    \n",
    "    for tweet in textdata:\n",
    "        tweet = tweet.lower()\n",
    "        \n",
    "        # Replace all URls with 'URL'\n",
    "        tweet = re.sub(urlPattern,' URL',tweet)\n",
    "        # Replace all emojis.\n",
    "        for emoji in emojis.keys():\n",
    "            tweet = tweet.replace(emoji, \"EMOJI\" + emojis[emoji])        \n",
    "        # Replace @USERNAME to 'USER'.\n",
    "        tweet = re.sub(userPattern,' USER', tweet)        \n",
    "        # Replace all non alphabets.\n",
    "        tweet = re.sub(alphaPattern, \" \", tweet)\n",
    "        # Replace 3 or more consecutive letters by 2 letter.\n",
    "        tweet = re.sub(sequencePattern, seqReplacePattern, tweet)\n",
    "\n",
    "        tweetwords = ''\n",
    "        for word in tweet.split():\n",
    "            # Checking if the word is a stopword.\n",
    "            #if word not in stopwordlist:\n",
    "            if len(word)>1:\n",
    "                # Lemmatizing the word.\n",
    "                word = wordLemm.lemmatize(word)\n",
    "                tweetwords += (word+' ')\n",
    "            \n",
    "        processedText.append(tweetwords)\n",
    "        \n",
    "    return processedText"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Message Text Process Function:\n",
    "\n",
    "This function use for preparing individual text samples for natural language processing tasks (sentiment analysis). A common technique for removing noise and irrelevant information from text data before processing it with machine learning models. The text preprocessing steps performed by this function include:\n",
    "\n",
    "- Removing all punctuation characters\n",
    "- Splitting the resulting text into a list of individual words\n",
    "- Removing all stop words (common words that are unlikely to be useful for NLP tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def message_text_process(mess):\n",
    "    no_punctuation = [char for char in mess if char not in string.punctuation]\n",
    "    no_punctuation = ''.join(no_punctuation)\n",
    "    return [word for word in no_punctuation.split() if word.lower() \n",
    "            not in stopwords.words('english')]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code segment initializes a CountVectorizer object vec with a maximum number of features of 10,000, fits it to the cleaned text data from the data using the fit() method, and then splits the data into training and validation sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count vectorizer\n",
    "vec = CountVectorizer(max_features=10000)\n",
    "vec.fit(df['clean_text'])\n",
    "\n",
    "# split dataset into train and validation sets\n",
    "trn, val = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "# transform text into sparse matrix using count vectorizer\n",
    "trn_abs = vec.transform(trn['clean_text'])\n",
    "val_abs = vec.transform(val['clean_text'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code is using the One-vs-Rest strategy for multi-class classification using logistic regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.948947659078358"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "\n",
    "# Instantiate a OneVsRestClassifier with a LogisticRegression model\n",
    "clf = OneVsRestClassifier(LogisticRegression(C=10, n_jobs=-1))\n",
    "\n",
    "# Fit the classifier on the training set\n",
    "clf.fit(trn_abs, trn['category'])\n",
    "\n",
    "# Predict on the validation set\n",
    "val_preds = clf.predict(val_abs)\n",
    "\n",
    "# Compute the F1 score on the validation set\n",
    "f1_score(val['category'], val_preds, average='micro')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the classifier has achieved a high level of accuracy in predicting the sentiment of the tweets in the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.948947659078358\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy score of the trained classifier on the validation set\n",
    "print(clf.score(val_abs, val['category']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.948947659078358"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the accuracy score on the validation set\n",
    "accuracy_score(val['category'], val_preds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The function below returns a matrix where each row represents the true label and each column represents the predicted label. \n",
    "- The diagonal elements of the matrix represent the number of correctly classified samples for each class\n",
    "- While the off-diagonal elements represent the number of misclassified samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9572,   264,   855],\n",
       "       [  198, 16215,   231],\n",
       "       [  687,   261, 20608]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(val['category'], val_preds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case:\n",
    "- First row and column represent the negative class (-1) \n",
    "- Second row and column represent the neutral class (0)\n",
    "- Third row and column represent the positive class (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.92      0.90      0.91     10691\n",
      "         0.0       0.97      0.97      0.97     16644\n",
      "         1.0       0.95      0.96      0.95     21556\n",
      "\n",
      "    accuracy                           0.95     48891\n",
      "   macro avg       0.94      0.94      0.94     48891\n",
      "weighted avg       0.95      0.95      0.95     48891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This report is useful for evaluating the performance of a classifier and identifying areas for improvement.\n",
    "print(classification_report(val['category'], val_preds))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report:\n",
    "\n",
    "- The report includes precision, recall, F1-score metrics, and weighted average for each class (-1.0, 0.0, and 1.0).\n",
    "- It also shows the support which is the number of samples in each class in the validation set.\n",
    "\n",
    "## Output:\n",
    "\n",
    "- From the output, we can see that the model has <strong>good</strong> precision, recall, and F1-scores for all classes.\n",
    "- An overall accuracy of <strong>95%</strong>. \n",
    "- The macro average F1-score and weighted average F1-score are both <strong>0.94</strong>, indicating a balanced performance across all classes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "# example text to predict the sentiment for\n",
    "text = \"I really enjoyed the movie. The acting was great and the plot was interesting.\"\n",
    "\n",
    "# transform the text using the same tf-idf vectorizer\n",
    "text_abs = vec.transform([text])\n",
    "\n",
    "# predict the sentiment of the text\n",
    "pred = clf.predict(text_abs)\n",
    "\n",
    "# print the predicted sentiment\n",
    "if pred == -1:\n",
    "    print('Negative')\n",
    "elif pred == 0:\n",
    "    print('Neutral')\n",
    "else:\n",
    "    print('Positive')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative\n"
     ]
    }
   ],
   "source": [
    "text = \"I am feeling really sad and disappointed about the news, it's just heartbreaking. I hope things will get better soon.\"\n",
    "\n",
    "# transform the text using the same tf-idf vectorizer\n",
    "text_abs = vec.transform([text])\n",
    "\n",
    "# predict the sentiment of the text\n",
    "pred = clf.predict(text_abs)\n",
    "\n",
    "# print the predicted sentiment\n",
    "if pred == -1:\n",
    "    print('Negative')\n",
    "elif pred == 0:\n",
    "    print('Neutral')\n",
    "else:\n",
    "    print('Positive')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neutral sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral\n"
     ]
    }
   ],
   "source": [
    "text = \"The weather today is partly cloudy with a chance of rain later in the evening.\"\n",
    "\n",
    "# transform the text using the same tf-idf vectorizer\n",
    "text_abs = vec.transform([text])\n",
    "\n",
    "# predict the sentiment of the text\n",
    "pred = clf.predict(text_abs)\n",
    "\n",
    "# print the predicted sentiment\n",
    "if pred == -1:\n",
    "    print('Negative')\n",
    "elif pred == 0:\n",
    "    print('Neutral')\n",
    "else:\n",
    "    print('Positive')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
