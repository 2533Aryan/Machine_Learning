{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembles Assignment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances: 569\n",
      "Number of features: 30\n",
      "Number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load the breast cancer dataset\n",
    "breast_cancer = load_breast_cancer()\n",
    "\n",
    "# Print the number of instances and features in the dataset\n",
    "print(\"Number of instances:\", breast_cancer.data.shape[0])\n",
    "print(\"Number of features:\", breast_cancer.data.shape[1])\n",
    "print(\"Number of classes:\", len(set(breast_cancer.target)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of the data:\n",
    "- This code loads the breast cancer dataset from the scikit-learn library, which contains data on breast cancer tumors. \n",
    "- The number of classes in the dataset is 2. \n",
    "- The classes are binary, indicating whether a breast mass is benign or malignant.\n",
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of classification task:\n",
    "\n",
    "- I am performing <strong>binary classification</strong> as there are only two possible classes for each instance - malignant or benign.\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide data into training & testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = breast_cancer.data, breast_cancer.target\n",
    "\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "        train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing classification algorithms using Pipelines & Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-fold cross validation:\n",
      "\n",
      "Accuracy: 0.97 Stdev: 0.029 Time: 0.166 [SVM]\n",
      "Accuracy: 0.91 Stdev: 0.059 Time: 0.285 [Decision tree]\n",
      "Accuracy: 0.95 Stdev: 0.044 Time: 0.445 [KNN]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "\n",
    "\n",
    "pipe1 = make_pipeline(StandardScaler(), SVC(kernel='linear', C=1.0, random_state=1))\n",
    "\n",
    "pipe2 = make_pipeline(DecisionTreeClassifier(max_depth=8,\n",
    "                                             criterion='entropy',\n",
    "                                             random_state=0))\n",
    "\n",
    "pipe3 = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=15,\n",
    "                                                             p=2,\n",
    "                                                             metric='minkowski'))\n",
    "\n",
    "\n",
    "clf_labels = ['SVM', 'Decision tree', 'KNN']\n",
    "\n",
    "print('20-fold cross validation:\\n')\n",
    "for clf, label in zip([pipe1, pipe2, pipe3], clf_labels):\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    scores = cross_val_score(estimator=clf,\n",
    "                             X=X_train,\n",
    "                             y=y_train,\n",
    "                             cv=20,\n",
    "                             scoring='accuracy')\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    print(\"Accuracy: \" + str(round(scores.mean(), 2)) + \n",
    "          \" Stdev: \" + str(round(scores.std(), 3)) +\n",
    "          \" Time: \" + str(round(end_time - start_time, 3)) +\n",
    "          \" [\" + label + \"]\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptions of the models used in each pipelines:\n",
    "\n",
    "- Pipe 1: <strong>SVM classifier</strong> using a linear kernel and configured with a regularization parameter C of 1.0 and a random state of 1.\n",
    "- Pipe 2: <strong>Decision Tree Classifier</strong> is configured with a maximum depth of 8, uses entropy as the splitting criterion, and a random state of 0.\n",
    "- Pipe 3: <strong>K-Nearest Neighbors (KNN) classifier</strong> is configured with n_neighbors equal to 15, p parameter to 2, metric parameter as 'minkowski'.\n",
    "\n",
    "Note that data preprocessing step has been done in pipe 1 and pipe 3 that scales the data using the <strong>StandardScaler</strong> method\n",
    "\n",
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the performance of three models:\n",
    "\n",
    "- Above code snippet also performs a <strong>20-fold cross-validation</strong> using three different models (SVM, Decision Tree, & KNN).\n",
    "- <strong>cross_val_score()</strong> function is used to evaluate the accuracy of the current model (clf) using 'accuracy' as scoring parameter.\n",
    "- The <strong>mean</strong> and <strong>standard deviation</strong> of these accuracy scores are also calculated.\n",
    "- <strong>Evaluation time</strong> is also calculated (it varies and dependent on computer it runs)\n",
    "\n",
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Results:\n",
    "\n",
    "- <strong>SVM</strong> achieved the highest accuracy of 0.97, with a low standard deviation of 0.029, and it took the least amount of time to train and evaluate the model on each fold, with an average time of 0.192 (in my machine - it varies).\n",
    "<br>\n",
    "\n",
    "- <strong>Decision Tree</strong> achieved an accuracy of 0.91, which is lower than SVM, and has a higher standard deviation of 0.059. It took longer than SVM to train and evaluate the model on each fold, with an average time of 0.327 (in my machine - it varies).\n",
    "<br>\n",
    "\n",
    "- <strong>KNN</strong>The KNN algorithm achieved an accuracy of 0.95, which is higher than the Decision Tree but lower than SVM, and it took the longest time to train and evaluate the model on each fold, with an average time of 0.565 (in my machine - it varies).\n",
    "<br>\n",
    "\n",
    "In general, the SVM algorithm seems to have the best overall performance, with the highest accuracy, lowest standard deviation, and shortest training and evaluation time. \n",
    "\n",
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Learning with Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-fold cross validation:\n",
      "\n",
      "Accuracy: 0.97 Stdev: 0.029 Time: 0.172 [SVM]\n",
      "Accuracy: 0.91 Stdev: 0.059 Time: 0.267 [Decision tree]\n",
      "Accuracy: 0.95 Stdev: 0.044 Time: 0.42 [KNN]\n",
      "Accuracy: 0.96 Stdev: 0.042 Time: 0.814 [Majority voting]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "mv_clf = VotingClassifier(estimators=[('p', pipe1), ('dt', pipe2), ('kn', pipe3)])\n",
    "\n",
    "clf_labels += ['Majority voting']\n",
    "all_clf = [pipe1, pipe2, pipe3, mv_clf]\n",
    "\n",
    "print('20-fold cross validation:\\n')\n",
    "for clf, label in zip(all_clf, clf_labels):\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    scores = cross_val_score(estimator=clf,\n",
    "                             X=X_train,\n",
    "                             y=y_train,\n",
    "                             cv=20,\n",
    "                             scoring='accuracy')\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(\"Accuracy: \" + str(round(scores.mean(), 2)) + \n",
    "          \" Stdev: \" + str(round(scores.std(), 3)) +\n",
    "          \" Time: \" + str(round(end_time - start_time, 3)) +          \n",
    "          \" [\" + label + \"]\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of the ensemble method:\n",
    "- I used an ensemble method called <strong>Majority Voting</strong>. \n",
    "- The <strong>VotingClassifier</strong> class is used to combine the predictions of three different pipelines into a single prediction by taking the majority vote of their predicted class labels.\n",
    "- By combining them, the ensemble can benefit from the strengths of each individual model while reducing the impact of any weaknesses."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of cross-validation results:\n",
    "- The results show the accuracy and standard deviation of each algorithm, as well as the time it took to run each algorithm. \n",
    "<br>\n",
    "\n",
    "- <strong>SVM</strong> has the highest accuracy of 0.97 with a standard deviation of 0.029 and took the least time to run, 0.196 seconds. \n",
    "<br>\n",
    "\n",
    "- <strong>Decision Tree</strong> has an accuracy of 0.91 with a higher standard deviation of 0.059 and took longer to run, 0.267 seconds. \n",
    "<br>\n",
    "\n",
    "- <strong>KNN</strong> has an accuracy of 0.95 with a standard deviation of 0.044 and took longer to run than SVM, 0.477 seconds. \n",
    "<br>\n",
    "\n",
    "- <strong>Majority Voting</strong> has an accuracy of 0.96 with a standard deviation of 0.042 and took the longest time to run, 0.901 seconds.\n",
    "<br>\n",
    "\n",
    "In summary, SVM seems to be the best performing algorithm in terms of accuracy, standard deviation, and computation time, while Decision Tree has the lowest accuracy and the highest standard deviation. KNN and Majority Voting have moderate accuracy and standard deviation but took longer to run than SVM."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individually train each of the pipelines & their performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n",
      "Misclassified test set examples: 8\n",
      "Out of a total of: 171\n",
      "Accuracy: 0.9532163742690059\n"
     ]
    }
   ],
   "source": [
    "pipe1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe1.predict(X_test)\n",
    "\n",
    "print('SVM:')\n",
    "\n",
    "print('Misclassified test set examples:', (y_test != y_pred).sum())\n",
    "print('Out of a total of:', y_test.shape[0])\n",
    "print('Accuracy:', pipe1.score(X_test, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree:\n",
      "Misclassified test set examples: 9\n",
      "Out of a total of: 171\n",
      "Accuracy: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "pipe2.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe2.predict(X_test)\n",
    "\n",
    "print('Decision Tree:')\n",
    "\n",
    "print('Misclassified test set examples:', (y_test != y_pred).sum())\n",
    "print('Out of a total of:', y_test.shape[0])\n",
    "print('Accuracy:', pipe2.score(X_test, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN:\n",
      "Misclassified test set examples: 8\n",
      "Out of a total of: 171\n",
      "Accuracy: 0.9532163742690059\n"
     ]
    }
   ],
   "source": [
    "pipe3.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe3.predict(X_test)\n",
    "\n",
    "print('KNN:')\n",
    "\n",
    "print('Misclassified test set examples:', (y_test != y_pred).sum())\n",
    "print('Out of a total of:', y_test.shape[0])\n",
    "print('Accuracy:', pipe3.score(X_test, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Voting:\n",
      "Misclassified test set examples: 8\n",
      "Out of a total of: 171\n",
      "Accuracy: 0.9532163742690059\n"
     ]
    }
   ],
   "source": [
    "mv_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = mv_clf.predict(X_test)\n",
    "\n",
    "print('Majority Voting:')\n",
    "\n",
    "print('Misclassified test set examples:', (y_test != y_pred).sum())\n",
    "print('Out of a total of:', y_test.shape[0])\n",
    "print('Accuracy:', mv_clf.score(X_test, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of the results of testing on the testing data:\n",
    "\n",
    "The results of testing on the testing data show that all four models (SVM, decision tree, KNN, and majority voting) have high accuracy in predicting the test set examples.\n",
    "<br>\n",
    "\n",
    "- The <strong>SVM</strong> model achieved an accuracy of 0.953, with only 8 misclassified test set examples out of a total of 171. \n",
    "<br>\n",
    "\n",
    "- The <strong>KNN</strong> and <strong>majority voting</strong> models also achieved an accuracy of 0.953, with only 8 misclassified examples each. \n",
    "<br>\n",
    "\n",
    "- The <strong>decision tree</strong> model achieved a slightly lower accuracy of 0.947, with 9 misclassified examples.\n",
    "\n",
    "Overall, the testing results are <strong>consistent</strong> with those of cross-validation, which showed high accuracy for all four models. However, the testing results do show some variation in accuracy compared to the cross-validation results, particularly for the decision tree model. Nonetheless, all models performed well on the testing data, indicating their potential usefulness for predicting new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
